import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, mean_squared_error
from collections import Counter
import altair as alt

# 1. DÃ©finition du problÃ¨me
st.title("ğŸ”§ Analyse PrÃ©dictive des Dysfonctionnements - UMS PASTA")
st.markdown("""
Ce tableau de bord permet de **prÃ©dire les probabilitÃ©s de dysfonctionnement** des Ã©quipements 
Ã  partir des donnÃ©es historiques des temps d'arrÃªt.
""")

# 2. Collecte des donnÃ©es
st.sidebar.markdown("## ğŸ“Š DonnÃ©es Ã  analyser")
uploaded_file = st.sidebar.file_uploader(
    label="ğŸ“**SÃ©lectionnez un fichier CSV :**", 
    type=["csv"], 
    help="Format acceptÃ© : .csv uniquement"
)
st.sidebar.info("ğŸ“ Le fichier doit contenir les colonnes : Date, Equipements, Temps d'immobilisation, etc.")

# === Ã‰TAPE 1 : Chargement du fichier ===
if uploaded_file:
    if st.button("âœ… Ã‰tape 1 : Charger et afficher les premiÃ¨res lignes"):
        df = pd.read_csv(uploaded_file)
        st.success("Fichier chargÃ© avec succÃ¨s !")
        st.write(df.head())

        # Nettoyage des Ã©quipements
        def nettoyer_equipements(df):
            df['Equipements'] = df['Equipements'].str.strip().str.lower().str.replace(r'\s+', ' ', regex=True)
            return df

        df = nettoyer_equipements(df)

        # Conversion date en mois
        if not np.issubdtype(df['Date'].dtype, np.number):
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.month

        st.session_state.df = df  # Sauvegarde pour Ã©tapes suivantes
        
# === Ã‰TAPE 2 : PrÃ©traitement et agrÃ©gation ===
if "df" in st.session_state:
    if st.button("âœ… Ã‰tape 2 : PrÃ©traitement et agrÃ©gation"):
        df = st.session_state.df
        premiers = df[df['Date'] <= 6]
        derniers = df[df['Date'] > 6]

        def calculer_aggregat(df_):
            return df_.groupby('Equipements').agg(
                RÃ©currence=('Equipements', 'size'),
                Temps_total=("Temps D'immobilisation", 'sum')
            ).reset_index()

        agg_premiers = calculer_aggregat(premiers)
        agg_derniers = calculer_aggregat(derniers)

        st.session_state.agg_premiers = agg_premiers
        st.session_state.agg_derniers = agg_derniers

        st.subheader("ğŸ“Š DonnÃ©es AgrÃ©gÃ©es - 6 Premiers Mois")
        st.dataframe(agg_premiers)
        
# === Ã‰TAPE 3 : Feature Engineering ===
if "agg_premiers" in st.session_state:
    st.sidebar.subheader("ğŸ”§ Ã‰tape 3 : Feature Engineering")
    threshold = st.sidebar.slider("ğŸ“ Seuil de rÃ©currence", 1, 20, 3)

    if st.button("âœ… Appliquer le seuil et gÃ©nÃ©rer les cibles"):
        def preprocess(df, t):
            df = df.rename(columns={"RÃ©currence": "Recurrence", "Temps_total": "Total_Time"})
            df["Dysfunction"] = (df["Recurrence"] > t).astype(int)
            return df

        agg_premiers = preprocess(st.session_state.agg_premiers.copy(), threshold)
        agg_derniers = preprocess(st.session_state.agg_derniers.copy(), threshold)

        X_premiers = agg_premiers[["Recurrence", "Total_Time"]]
        y_premiers = agg_premiers["Dysfunction"]
        X_derniers = agg_derniers[["Recurrence", "Total_Time"]]
        y_derniers = agg_derniers["Dysfunction"]

        scaler = StandardScaler()
        X_premiers_scaled = scaler.fit_transform(X_premiers)
        X_derniers_scaled = scaler.transform(X_derniers)

        st.session_state.X_premiers_scaled = X_premiers_scaled
        st.session_state.X_derniers_scaled = X_derniers_scaled
        st.session_state.y_premiers = y_premiers
        st.session_state.agg_premiers_feat = agg_premiers
        st.session_state.agg_derniers_feat = agg_derniers

        st.success("Seuil appliquÃ© et variables prÃªtes pour l'entraÃ®nement.")

# === Ã‰TAPE 4 : EntraÃ®nement des modÃ¨les ===
if "X_premiers_scaled" in st.session_state:
    if st.button("âœ… Ã‰tape 4 : EntraÃ®ner les modÃ¨les"):
        models = {
            "Logistic Regression": LogisticRegression(max_iter=1000),
            "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
            "Gradient Boosting": GradientBoostingClassifier(random_state=42)
        }

        results = {}
        for name, model in models.items():
            model.fit(st.session_state.X_premiers_scaled, st.session_state.y_premiers)
            y_proba = model.predict_proba(st.session_state.X_premiers_scaled)[:, 1]
            results[name] = y_proba

        probs_df = pd.DataFrame(results, index=st.session_state.agg_premiers_feat["Equipements"])
        st.session_state.probs_df = probs_df

        st.success("ModÃ¨les entraÃ®nÃ©s avec succÃ¨s.")
        st.subheader("ğŸ“ˆ ProbabilitÃ©s prÃ©dites")
        st.dataframe(probs_df)
        
# === Ã‰TAPE 5 : Ã‰valuation des prÃ©dictions ===
if "probs_df" in st.session_state:
    if st.button("âœ… Ã‰tape 5 : Comparer avec les donnÃ©es passÃ©es"):
        agg_derniers = st.session_state.agg_derniers_feat.copy()
        agg_derniers["Recurrence_Bin"] = pd.cut(agg_derniers["Recurrence"], bins=5, labels=False)
        agg_derniers["Total_Time_Bin"] = pd.cut(agg_derniers["Total_Time"], bins=5, labels=False)

        observed_probs = agg_derniers.groupby(["Recurrence_Bin", "Total_Time_Bin"])["Dysfunction"].mean().reset_index()
        observed_probs = observed_probs.rename(columns={"Dysfunction": "Observed_Probability"})

        agg_derniers = agg_derniers.merge(observed_probs, on=["Recurrence_Bin", "Total_Time_Bin"], how="left")
        probs_past = agg_derniers[["Equipements", "Observed_Probability"]].set_index("Equipements")

        common_index = st.session_state.probs_df.index.intersection(probs_past.index)
        diff_df = pd.DataFrame(index=common_index)

        for model_name in st.session_state.probs_df.columns:
            diff_df[f"{model_name}"] = (
                probs_past.loc[common_index]["Observed_Probability"] -
                st.session_state.probs_df.loc[common_index][model_name]
            )
        
        # ğŸ”„ Sauvegarde pour Ã©tape 6
        st.session_state.diff_df = diff_df

        st.subheader("ğŸ“‰ Ã‰carts entre prÃ©dictions et observations")
        st.dataframe(diff_df)
        
        
        # PrÃ©paration des donnÃ©es au format long pour Altair
        diff_df_abs = diff_df.abs().reset_index().rename(columns={"index": "Equipements"})
        diff_long_bar = diff_df_abs.melt(id_vars="Equipements", var_name="ModÃ¨le", value_name="Ã‰cart")

        # CrÃ©ation du graphique barres Altair avec padding personnalisÃ©
        bar_chart = alt.Chart(diff_long_bar).mark_bar().encode(
            x=alt.X('Equipements:N', title='Ã‰quipements', sort=None, axis=alt.Axis(labelAngle=90,labelFontSize=11)),
            y=alt.Y('Ã‰cart:Q', title='Ã‰cart Absolu'),
            color='ModÃ¨le:N',
            tooltip=['Equipements', 'ModÃ¨le', 'Ã‰cart']
        ).properties(
            width=1100,
            height=600,
            title="Ã‰carts Absolus entre PrÃ©dictions et Observations",
            padding={'left': 30, 'top': 10, 'right': 5, 'bottom': 45},
        ).configure_axis(
            labelFontSize=12,
            titleFontSize=14,
            titlePadding=10
        ).configure_legend(
            orient='bottom',
            title=None,
            labelFontSize=15
        ).interactive()

        st.altair_chart(bar_chart, use_container_width=True)
        
        # Line chart interactif avec points foncÃ©s (Altair)
        st.write("ğŸ“ˆ Ã‰volution interactive des Ã©carts par modÃ¨le")

        # Mise en forme des donnÃ©es pour Altair
        diff_df_reset = diff_df.abs().reset_index().rename(columns={"index": "Equipements"})
        diff_long = diff_df_reset.melt(id_vars="Equipements", var_name="ModÃ¨le", value_name="Ã‰cart")

        line_chart = alt.Chart(diff_long).mark_line(point=alt.OverlayMarkDef(color='black')).encode(
            x=alt.X('Equipements:N', sort=None, title='Ã‰quipements',axis=alt.Axis(labelAngle=90,labelFontSize=11)),
            y=alt.Y('Ã‰cart:Q', title='Ã‰cart Absolu'),
            color='ModÃ¨le:N',
            tooltip=['Equipements', 'ModÃ¨le', 'Ã‰cart']
        ).properties(
            width=1100,
            height=600,
            title="",
            padding={'left': 30, 'top': 10, 'right': 5, 'bottom': 45}  # ğŸ› ï¸ Ajoute de l'espace Ã  gauche
        ).configure_legend(
            orient='bottom',
            title=None,
            labelFontSize=15,
            labelLimit=200).interactive()

        st.altair_chart(line_chart, use_container_width=True)


        # Ã‰valuation finale
        avg_diff = {col: diff_df[col].abs().mean() for col in diff_df.columns}
        st.subheader("ğŸ“Š RÃ©sumÃ© de l'Ã©cart moyen par modÃ¨le")
        st.write(pd.DataFrame.from_dict(avg_diff, orient='index', columns=["Ã‰cart Moyen Probabiliste"]))
        
# === Ã‰TAPE 6 : Affichage du tableau de bord global structurÃ© ===
if (
    "probs_df" in st.session_state and 
    "agg_derniers_feat" in st.session_state and 
    "diff_df" in st.session_state
):
    # Gestion de l'Ã©tat persistant du bouton pour afficher le dashboard
    if st.button("ğŸ“Š AccÃ©der au Tableau de Bord Complet"):
        st.session_state.show_dashboard = True

    if st.session_state.get("show_dashboard", False):
        st.markdown("## ğŸ§­ Tableau de Bord PrÃ©dictif Complet")

        # Onglets pour organiser les vues
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“ˆ ProbabilitÃ©s PrÃ©dites",
            "ğŸ“‰ Ã‰carts Absolus (Barres)",
            "ğŸ“‰ Ã‰carts Absolus (Lignes)",
            "ğŸ“Š RÃ©sumÃ© & Export"
        ])

        with st.sidebar:
            st.markdown("## ğŸ” Filtres AvancÃ©s")

            # Filtrer par modÃ¨le
            modeles = st.session_state.probs_df.columns.tolist()
            selected_modeles = st.multiselect("ModÃ¨les Ã  afficher :", modeles, default=modeles)

            # Filtrer par intervalles de probabilitÃ©
            prob_min, prob_max = st.slider(
                "ğŸ¯ Filtrer par ProbabilitÃ© Moyenne :", 0.0, 1.0, (0.0, 1.0), 0.01
            )

            # Trier
            #tri_option = st.selectbox(
                #"ğŸ”½ Trier les Ã©quipements par :", 
                #["Aucun", "ProbabilitÃ© Croissante", "ProbabilitÃ© DÃ©croissante"]
            #)

        # Construction de la table de probabilitÃ©s moyennes
        probs_df = st.session_state.probs_df[selected_modeles].copy()
        probs_df["Moyenne"] = probs_df.mean(axis=1)

        # Filtrage par intervalle de probabilitÃ©
        filtered_probs_df = probs_df[
            (probs_df["Moyenne"] >= prob_min) & (probs_df["Moyenne"] <= prob_max)
        ].copy()

        # Tri des Ã©quipements
        #if tri_option == "ProbabilitÃ© Croissante":
            #filtered_probs_df = filtered_probs_df.sort_values("Moyenne", ascending=True)
        #elif tri_option == "ProbabilitÃ© DÃ©croissante":
            #filtered_probs_df = filtered_probs_df.sort_values("Moyenne", ascending=False)

        # SÃ©lection sÃ©curisÃ©e des Ã©quipements prÃ©sents dans les deux datasets
        available_equipements = st.session_state.diff_df.index.intersection(filtered_probs_df.index)
        filtered_probs_df = filtered_probs_df.loc[available_equipements]
        filtered_diff_df = st.session_state.diff_df.loc[available_equipements][selected_modeles]
        selected_equipements = available_equipements.tolist()

        # Mise au format long pour les graphiques Altair
        filtered_probs_long = filtered_probs_df[selected_modeles].reset_index().melt(
            id_vars="Equipements", var_name="ModÃ¨le", value_name="ProbabilitÃ©"
        )
        filtered_diff_long = filtered_diff_df.abs().reset_index().rename(
            columns={"index": "Equipements"}
        ).melt(id_vars="Equipements", var_name="ModÃ¨le", value_name="Ã‰cart")

        # --- Onglet 1 : ProbabilitÃ©s
        with tab1:
            st.subheader("ğŸ“ˆ ProbabilitÃ©s PrÃ©dites")
            st.dataframe(filtered_probs_df[selected_modeles])

            prob_chart = alt.Chart(filtered_probs_long).mark_bar().encode(
                x=alt.X('Equipements:N', sort=None, axis=alt.Axis(labelAngle=90, labelFontSize=11)),
                y=alt.Y('ProbabilitÃ©:Q'),
                color='ModÃ¨le:N',
                tooltip=['Equipements', 'ModÃ¨le', 'ProbabilitÃ©']
            ).properties(width=1100, height=500)

            st.altair_chart(prob_chart, use_container_width=True)

        # --- Onglet 2 : Ã‰carts absolus - Barres
        with tab2:
            st.subheader("ğŸ“‰ Ã‰carts Absolus - Barres")
            bar_chart = alt.Chart(filtered_diff_long).mark_bar().encode(
                x=alt.X('Equipements:N', sort=None, axis=alt.Axis(labelAngle=90, labelFontSize=11)),
                y='Ã‰cart:Q',
                color='ModÃ¨le:N',
                tooltip=['Equipements', 'ModÃ¨le', 'Ã‰cart']
            ).properties(width=1100, height=500)

            st.altair_chart(bar_chart, use_container_width=True)

        # --- Onglet 3 : Ã‰carts absolus - Lignes
        with tab3:
            st.subheader("ğŸ“‰ Ã‰carts Absolus - Lignes")
            line_chart = alt.Chart(filtered_diff_long).mark_line(
                point=alt.OverlayMarkDef(color='black')
            ).encode(
                x=alt.X('Equipements:N', sort=None, axis=alt.Axis(labelAngle=90, labelFontSize=11)),
                y='Ã‰cart:Q',
                color='ModÃ¨le:N',
                tooltip=['Equipements', 'ModÃ¨le', 'Ã‰cart']
            ).properties(width=1100, height=500)

            st.altair_chart(line_chart, use_container_width=True)

        # --- Onglet 4 : RÃ©sumÃ© & Export
        with tab4:
            st.subheader("ğŸ“Š Ã‰cart Moyen par ModÃ¨le (Ã‰quipements filtrÃ©s)")
            avg_filtered = {
                col: filtered_diff_df[col].abs().mean() for col in filtered_diff_df.columns
            }
            st.write(pd.DataFrame.from_dict(avg_filtered, orient='index', columns=["Ã‰cart Moyen Probabiliste"]))

            st.markdown("### ğŸ“¥ TÃ©lÃ©charger les donnÃ©es filtrÃ©es")
            col1, col2 = st.columns(2)
            with col1:
                csv_probs = filtered_probs_df[selected_modeles].to_csv(index=True).encode('utf-8')
                st.download_button("â¬‡ï¸ Exporter ProbabilitÃ©s", csv_probs, file_name="probabilites_filtrees.csv", mime="text/csv")
            with col2:
                csv_diff = filtered_diff_df.to_csv(index=True).encode('utf-8')
                st.download_button("â¬‡ï¸ Exporter Ã‰carts", csv_diff, file_name="ecarts_filtrees.csv", mime="text/csv")

else:
    st.warning("Veuillez charger un fichier CSV pour commencer.")